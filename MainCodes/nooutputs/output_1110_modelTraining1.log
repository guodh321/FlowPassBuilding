1699634820.3154457
ConvAutoencoder5Conv2ds(
  (encoder): Sequential(
    (0): Conv2d(2, 16, kernel_size=(2, 2), stride=(2, 2))
    (1): ReLU(inplace=True)
    (2): Conv2d(16, 32, kernel_size=(2, 2), stride=(2, 2))
    (3): ReLU(inplace=True)
    (4): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))
    (5): ReLU(inplace=True)
    (6): Conv2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
    (7): ReLU(inplace=True)
    (8): Conv2d(32, 16, kernel_size=(2, 2), stride=(2, 2))
    (9): ReLU(inplace=True)
  )
  (decoder): Sequential(
    (0): ConvTranspose2d(16, 32, kernel_size=(2, 2), stride=(2, 2))
    (1): ReLU(inplace=True)
    (2): ConvTranspose2d(32, 64, kernel_size=(2, 2), stride=(2, 2))
    (3): ReLU(inplace=True)
    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
    (5): ReLU(inplace=True)
    (6): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))
    (7): ReLU(inplace=True)
    (8): ConvTranspose2d(16, 2, kernel_size=(2, 2), stride=(2, 2))
    (9): Identity()
  )
)
Epoch [1/200], Loss: 0.2466
Epoch [2/200], Loss: 0.0903
Epoch [3/200], Loss: 0.0658
Epoch [4/200], Loss: 0.0621
Epoch [5/200], Loss: 0.0612
Epoch [6/200], Loss: 0.0609
Epoch [7/200], Loss: 0.0605
Epoch [8/200], Loss: 0.0600
Epoch [9/200], Loss: 0.0593
Epoch [10/200], Loss: 0.0587
Epoch [11/200], Loss: 0.0576
Epoch [12/200], Loss: 0.0571
Epoch [13/200], Loss: 0.0568
Epoch [14/200], Loss: 0.0566
Epoch [15/200], Loss: 0.0563
Epoch [16/200], Loss: 0.0562
Epoch [17/200], Loss: 0.0561
Epoch [18/200], Loss: 0.0560
Epoch [19/200], Loss: 0.0558
Epoch [20/200], Loss: 0.0556
Epoch [21/200], Loss: 0.0550
Epoch [22/200], Loss: 0.0544
Epoch [23/200], Loss: 0.0536
Epoch [24/200], Loss: 0.0527
Epoch [25/200], Loss: 0.0520
Epoch [26/200], Loss: 0.0515
Epoch [27/200], Loss: 0.0511
Epoch [28/200], Loss: 0.0508
Epoch [29/200], Loss: 0.0505
Epoch [30/200], Loss: 0.0502
Epoch [31/200], Loss: 0.0499
Epoch [32/200], Loss: 0.0496
Epoch [33/200], Loss: 0.0492
Epoch [34/200], Loss: 0.0489
Epoch [35/200], Loss: 0.0486
Epoch [36/200], Loss: 0.0481
Epoch [37/200], Loss: 0.0477
Epoch [38/200], Loss: 0.0472
Epoch [39/200], Loss: 0.0471
Epoch [40/200], Loss: 0.0464
Epoch [41/200], Loss: 0.0460
Epoch [42/200], Loss: 0.0456
Epoch [43/200], Loss: 0.0445
Epoch [44/200], Loss: 0.0439
Epoch [45/200], Loss: 0.0435
Epoch [46/200], Loss: 0.0430
Epoch [47/200], Loss: 0.0425
Epoch [48/200], Loss: 0.0422
Epoch [49/200], Loss: 0.0418
Epoch [50/200], Loss: 0.0416
Epoch [51/200], Loss: 0.0411
Epoch [52/200], Loss: 0.0408
Epoch [53/200], Loss: 0.0405
Epoch [54/200], Loss: 0.0403
Epoch [55/200], Loss: 0.0402
Epoch [56/200], Loss: 0.0399
Epoch [57/200], Loss: 0.0397
Epoch [58/200], Loss: 0.0395
Epoch [59/200], Loss: 0.0394
Epoch [60/200], Loss: 0.0393
Epoch [61/200], Loss: 0.0391
Epoch [62/200], Loss: 0.0390
Epoch [63/200], Loss: 0.0390
Epoch [64/200], Loss: 0.0388
Epoch [65/200], Loss: 0.0386
Epoch [66/200], Loss: 0.0385
Epoch [67/200], Loss: 0.0385
Epoch [68/200], Loss: 0.0383
Epoch [69/200], Loss: 0.0383
Epoch [70/200], Loss: 0.0382
Epoch [71/200], Loss: 0.0380
Epoch [72/200], Loss: 0.0379
Epoch [73/200], Loss: 0.0378
Epoch [74/200], Loss: 0.0377
Epoch [75/200], Loss: 0.0376
Epoch [76/200], Loss: 0.0376
Epoch [77/200], Loss: 0.0375
Epoch [78/200], Loss: 0.0374
Epoch [79/200], Loss: 0.0373
Epoch [80/200], Loss: 0.0373
Epoch [81/200], Loss: 0.0372
Epoch [82/200], Loss: 0.0372
Epoch [83/200], Loss: 0.0370
Epoch [84/200], Loss: 0.0371
Epoch [85/200], Loss: 0.0369
Epoch [86/200], Loss: 0.0369
Epoch [87/200], Loss: 0.0369
Epoch [88/200], Loss: 0.0368
Epoch [89/200], Loss: 0.0368
Epoch [90/200], Loss: 0.0367
Epoch [91/200], Loss: 0.0366
Epoch [92/200], Loss: 0.0366
Epoch [93/200], Loss: 0.0365
Epoch [94/200], Loss: 0.0366
Epoch [95/200], Loss: 0.0365
Epoch [96/200], Loss: 0.0364
Epoch [97/200], Loss: 0.0364
Epoch [98/200], Loss: 0.0363
Epoch [99/200], Loss: 0.0365
Epoch [100/200], Loss: 0.0361
Epoch [101/200], Loss: 0.0358
Epoch [102/200], Loss: 0.0357
Epoch [103/200], Loss: 0.0356
Epoch [104/200], Loss: 0.0356
Epoch [105/200], Loss: 0.0355
Epoch [106/200], Loss: 0.0355
Epoch [107/200], Loss: 0.0355
Epoch [108/200], Loss: 0.0354
Epoch [109/200], Loss: 0.0353
Epoch [110/200], Loss: 0.0353
Epoch [111/200], Loss: 0.0353
Epoch [112/200], Loss: 0.0353
Epoch [113/200], Loss: 0.0352
Epoch [114/200], Loss: 0.0352
Epoch [115/200], Loss: 0.0351
Epoch [116/200], Loss: 0.0350
Epoch [117/200], Loss: 0.0350
Epoch [118/200], Loss: 0.0350
Epoch [119/200], Loss: 0.0349
Epoch [120/200], Loss: 0.0349
Epoch [121/200], Loss: 0.0349
Epoch [122/200], Loss: 0.0348
Epoch [123/200], Loss: 0.0348
Epoch [124/200], Loss: 0.0348
Epoch [125/200], Loss: 0.0347
Epoch [126/200], Loss: 0.0346
Epoch [127/200], Loss: 0.0346
Epoch [128/200], Loss: 0.0346
Epoch [129/200], Loss: 0.0346
Epoch [130/200], Loss: 0.0346
Epoch [131/200], Loss: 0.0348
Epoch [132/200], Loss: 0.0345
Epoch [133/200], Loss: 0.0345
Epoch [134/200], Loss: 0.0344
Epoch [135/200], Loss: 0.0343
Epoch [136/200], Loss: 0.0343
Epoch [137/200], Loss: 0.0344
Epoch [138/200], Loss: 0.0343
Epoch [139/200], Loss: 0.0342
Epoch [140/200], Loss: 0.0342
Epoch [141/200], Loss: 0.0342
Epoch [142/200], Loss: 0.0341
Epoch [143/200], Loss: 0.0342
Epoch [144/200], Loss: 0.0341
Epoch [145/200], Loss: 0.0341
Epoch [146/200], Loss: 0.0341
Epoch [147/200], Loss: 0.0340
Epoch [148/200], Loss: 0.0340
Epoch [149/200], Loss: 0.0339
Epoch [150/200], Loss: 0.0339
Epoch [151/200], Loss: 0.0339
Epoch [152/200], Loss: 0.0340
Epoch [153/200], Loss: 0.0339
Epoch [154/200], Loss: 0.0338
Epoch [155/200], Loss: 0.0338
Epoch [156/200], Loss: 0.0337
Epoch [157/200], Loss: 0.0337
Epoch [158/200], Loss: 0.0338
Epoch [159/200], Loss: 0.0337
Epoch [160/200], Loss: 0.0337
Epoch [161/200], Loss: 0.0336
Epoch [162/200], Loss: 0.0336
Epoch [163/200], Loss: 0.0336
Epoch [164/200], Loss: 0.0336
Epoch [165/200], Loss: 0.0335
Epoch [166/200], Loss: 0.0335
Epoch [167/200], Loss: 0.0335
Epoch [168/200], Loss: 0.0334
Epoch [169/200], Loss: 0.0335
Epoch [170/200], Loss: 0.0334
Epoch [171/200], Loss: 0.0334
Epoch [172/200], Loss: 0.0334
Epoch [173/200], Loss: 0.0334
Epoch [174/200], Loss: 0.0333
Epoch [175/200], Loss: 0.0333
Epoch [176/200], Loss: 0.0334
Epoch [177/200], Loss: 0.0333
Epoch [178/200], Loss: 0.0333
Epoch [179/200], Loss: 0.0333
Epoch [180/200], Loss: 0.0334
Epoch [181/200], Loss: 0.0332
Epoch [182/200], Loss: 0.0332
Epoch [183/200], Loss: 0.0331
Epoch [184/200], Loss: 0.0331
Epoch [185/200], Loss: 0.0331
Epoch [186/200], Loss: 0.0330
Epoch [187/200], Loss: 0.0330
Epoch [188/200], Loss: 0.0330
Epoch [189/200], Loss: 0.0330
Epoch [190/200], Loss: 0.0330
Epoch [191/200], Loss: 0.0330
Epoch [192/200], Loss: 0.0330
Epoch [193/200], Loss: 0.0329
Epoch [194/200], Loss: 0.0330
Epoch [195/200], Loss: 0.0329
Epoch [196/200], Loss: 0.0329
Epoch [197/200], Loss: 0.0329
Epoch [198/200], Loss: 0.0329
Epoch [199/200], Loss: 0.0328
Epoch [200/200], Loss: 0.0328
Training time: 12267.379184961319
Saved model path: /home/dg321/gitTest/PRI/irp/interpolation_code_example_2D/models/Velocity256_Compression_200epochs_32batchsize_lr0.003.pth
